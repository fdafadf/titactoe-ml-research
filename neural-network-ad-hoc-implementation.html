<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Neural Network ad hoc implementation</title>
    <link type="text/css" rel="stylesheet" href="default.css">
</head>
<body>
    <p><a href="https://github.com/fdafadf/titactoe-ml-research/tree/main/modules/ml">https://github.com/fdafadf/titactoe-ml-research/tree/main/modules/ml</a></p>
    <p>Tensor class decorates built-in array with few new methods:</p>
    <ul>
        <li>clone - returns deep copy of array.</li>
        <li>rand - returns random element.</li>
        <li>scale - multiplies all numerical values in array.</li>
        <li>translate - increments all numerical values in array.</li>
        <li>randomize - fills array with random values.</li>
        <li>mul - multiplies two arrays (mathematically, matrices).</li>
        <li>transpone - transposes an array.</li>
        <li>set - fills array with values of other array.</li>
        <li>apply - changes the values of an array by applying specified function.</li>
        <li>shuffle - shuffles items in an array.</li>
        <li>indexOfMax - returns the index of the largest element in the array.</li>
    </ul>
    <p>Network class contains:</p>
    <ul>
        <li>He - layer initialisation function.</li>
        <li>ReLU - as hardcoded activation function.</li>
        <li>The simplest gradient calculation.</li>
    </ul>
</body>
</html>